{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.neighbors import NearestNeighbors as NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful constants:\n",
    "infty = 1e100\n",
    "current_pair = (-2137, -2137)\n",
    "wanted_pair = (-2137, -2137)\n",
    "current_N = -1\n",
    "dists = []\n",
    "vecs = []\n",
    "neigh_number = 1 #will probably be changed during testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#metrics\n",
    "\n",
    "#general template:\n",
    "#arguments: pair of vectors of scores; these vectors should be dictionaries in form {anime_id : rating}\n",
    "\n",
    "#returns: distance between given vectors\n",
    "\n",
    "def normalized_dist(x, y) :\n",
    "    nonzero_indices = x.keys() & y.keys()\n",
    "    N = len(nonzero_indices)\n",
    "    \n",
    "    if(N == 0) :\n",
    "        return infty #defined at the beginning, check for that\n",
    "    \n",
    "    cut_x = np.array([x[ind] for ind in nonzero_indices])\n",
    "    cut_y = np.array([y[ind] for ind in nonzero_indices])\n",
    "    diff = cut_x - cut_y\n",
    "    \n",
    "    dist = np.sum(diff ** 2) / N\n",
    "    return dist\n",
    "\n",
    "def count_common_dist(x, y) :\n",
    "    nonzero_indices = x.keys() & y.keys()\n",
    "    N = len(nonzero_indices)\n",
    "    \n",
    "    if(N == 0) :\n",
    "        return infty #defined at the beginning, check for that\n",
    "    \n",
    "    return 1.0 / N\n",
    "\n",
    "def correlation_dist(x, y) :\n",
    "    nonzero_indices = x.keys() & y.keys()\n",
    "    N = len(nonzero_indices)\n",
    "    \n",
    "    if(N == 0) :\n",
    "        return infty #defined at the beginning, check for that\n",
    "    \n",
    "    cut_x = np.array([float(x[ind]) for ind in nonzero_indices])\n",
    "    cut_y = np.array([float(y[ind]) for ind in nonzero_indices])\n",
    "    \n",
    "    avg_x = np.average(cut_x)\n",
    "    avg_y = np.average(cut_y)\n",
    "    \n",
    "    cut_x -= np.full(N, avg_x)\n",
    "    cut_y -= np.full(N, avg_y)\n",
    "    \n",
    "    dot_x = np.dot(cut_x, cut_x)\n",
    "    dot_y = np.dot(cut_y, cut_y)\n",
    "    \n",
    "    if(min(dot_x, dot_y) < 1e-100) :\n",
    "        return infty\n",
    "    \n",
    "    dist = np.dot(cut_x, cut_y) / np.sqrt(dot_x * dot_y)\n",
    "    return dist\n",
    "\n",
    "def cosine_dist(x, y) :\n",
    "    nonzero_indices = x.keys() & y.keys()\n",
    "    N = len(nonzero_indices)\n",
    "    \n",
    "    if(N == 0) :\n",
    "        return infty #defined at the beginning, check for that\n",
    "    \n",
    "    cut_x = np.array([float(x[ind]) for ind in nonzero_indices])\n",
    "    cut_y = np.array([float(y[ind]) for ind in nonzero_indices])\n",
    "    \n",
    "    dist = np.dot(cut_x, cut_y) / np.sqrt(np.sum(cut_x ** 2) * np.sum(cut_y ** 2))\n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arguments: \n",
    "# x - main vector, vectors - all other vectors\n",
    "# dist - metric used (function), K - number of neighbors used to calculate the score\n",
    "\n",
    "#returns list of K (or less if there are less in total) neighbors\n",
    "def myKNN(x, vectors, dist, update, K) :\n",
    "    ret = []\n",
    "    global dists\n",
    "    global vecs\n",
    "    global current_N\n",
    "    \n",
    "    if(update == True) :\n",
    "        dists = []\n",
    "        current_N = len(vectors)\n",
    "        for i in range(0, current_N) :\n",
    "            dists.append((dist(x, vectors[i]), i))\n",
    "        \n",
    "        dists = sorted(dists)\n",
    "        vecs = vectors\n",
    "    else :\n",
    "        if(len(dists) != current_N) :\n",
    "            print(dupa)\n",
    "            return \"kupa\"\n",
    "    \n",
    "    K = min(K, current_N)\n",
    "    for i in range(0, K) :\n",
    "        ret.append(dists[i][1])\n",
    "    \n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arguments: \n",
    "# anime_id - index of user, user_vec - user's ratings as vector, vectors - other users' ratings as vectors\n",
    "# dist - metric used (function), K - number of neighbors used to calculate the score\n",
    "\n",
    "# returns score based on nearest neighbours\n",
    "def KNN_score(anime_id, user_vec, vectors, dist, update, K = 5) :\n",
    "    global vecs\n",
    "    neighbors = myKNN(user_vec, vectors, dist, update, K)\n",
    "    neigh_scores = np.array([vecs[nei][anime_id] for nei in neighbors])\n",
    "    \n",
    "    score = np.average(neigh_scores)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data\n",
    "records = pd.read_csv('rating.csv')\n",
    "records = records.to_numpy()\n",
    "\n",
    "users = 0\n",
    "animes = 0\n",
    "\n",
    "for r in records :\n",
    "    users = max(users, r[0])\n",
    "    animes = max(animes, r[1])\n",
    "\n",
    "#print(\"users:\", users, \"animes:\", animes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = [0] * (users + 1)\n",
    "ratings_with_minus_ones = [0] * (users + 1)\n",
    "count_anime = [0] * (users + 1)\n",
    "count_users = [0] * (animes + 1)\n",
    "\n",
    "for i in range(0, users + 1) :\n",
    "    ratings[i] = dict()\n",
    "    ratings_with_minus_ones[i] = dict()\n",
    "\n",
    "#optional: minus_one - new value for all -1s (0 means ignoring them)\n",
    "def parse_records(minus_one = -1) :\n",
    "    for r in records :\n",
    "        user_id, anime_id, rating = r\n",
    "        if(rating == -1) :\n",
    "            rating = minus_one\n",
    "        if(rating != 0) : \n",
    "            ratings_with_minus_ones[user_id][anime_id] = rating\n",
    "            if(rating != -1) :\n",
    "                ratings[user_id][anime_id] = rating\n",
    "                count_users[anime_id] += 1\n",
    "                count_anime[user_id] += 1\n",
    "                \n",
    "\n",
    "#argument: anime_id\n",
    "\n",
    "#returns: list of rating vectors of users who watched anime_id\n",
    "def cut_records(anime_id, include_minus_ones) :\n",
    "    result = []\n",
    "    \n",
    "    for user in range(1, users + 1) :\n",
    "        if(anime_id in ratings[user]) :\n",
    "            if(include_minus_ones == False) :\n",
    "                result.append(ratings[user])\n",
    "            else :\n",
    "                result.append(ratings_with_minus_ones[user])\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "parse_records()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arguments: user_id, anime_id\n",
    "#optional: if score should be rounded, if it is for testing purpouse\n",
    "\n",
    "#returns estimation of the score\n",
    "def estimate_score(user_id, anime_id, measure = normalized_dist, include_minus_ones = False, rounded = False, test = False) :    \n",
    "    temp = 0\n",
    "\n",
    "    if(test == True) :\n",
    "        temp = ratings[user_id].pop(anime_id, None)\n",
    "        if(temp == None) :\n",
    "            print(\"You sholud test on existing records! (try test = False)\")\n",
    "            return 2137.0\n",
    "    else :\n",
    "        if(anime_id in ratings[user_id]) :\n",
    "            print(\"Anime already rated (forgot test = False ?)\")\n",
    "            return ratings[user_id][anime_id]\n",
    "    \n",
    "    global current_pair\n",
    "    global wanted_pair\n",
    "    \n",
    "    watched = []\n",
    "    update = False\n",
    "    \n",
    "    wanted_pair = (user_id, anime_id)\n",
    "    \n",
    "    if(current_pair != wanted_pair) :\n",
    "        watched = cut_records(anime_id, include_minus_ones)\n",
    "        update = True\n",
    "        current_pair = wanted_pair\n",
    "            \n",
    "    if(include_minus_ones == False) :\n",
    "        user_vec = ratings[user_id]\n",
    "    else :\n",
    "        user_vec = ratings_with_minus_ones[user_id]\n",
    "        \n",
    "    answer = KNN_score(anime_id, user_vec, watched, measure, update, K = neigh_number)\n",
    "    \n",
    "    if(test == True) :\n",
    "        ratings[user_id][anime_id] = temp\n",
    "    \n",
    "    if(rounded == True) :\n",
    "        answer = np.rint(answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arguments: two np.array with equal lengths: estimated and expected ratings \n",
    "\n",
    "#returns: average of squared differences\n",
    "def error_avsq(estimated, real) :\n",
    "    return np.sum((estimated-real)**2) / len(real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional: user_bound, anime_bound, stop_bound\n",
    "\n",
    "#returns at most stop_bound pairs (user_id, anime_id) such that:\n",
    "# - used_id watched anime_id and rated it\n",
    "# - user_id watched at least user_bound animes\n",
    "# - anime id has been watched at least anime_bound times\n",
    "def select_popular_probe(user_bound = 30, anime_bound = 5000, stop_bound = 1000) :\n",
    "    ans = []\n",
    "    \n",
    "    perm = np.arange(len(records))\n",
    "    np.random.shuffle(perm)\n",
    "    \n",
    "    for p in perm :\n",
    "        user_id, anime_id, rating = records[p]\n",
    "        if(rating > 0 and count_anime[user_id] >= user_bound and count_users[anime_id] >= anime_bound) :\n",
    "            ans.append((user_id, anime_id))\n",
    "            if(len(ans) == stop_bound) :\n",
    "                break\n",
    "                \n",
    "    return ans\n",
    "\n",
    "def select_random_probe(stop_bound = 1000) :\n",
    "    return select_popular_probe(0, 0, stop_bound)\n",
    "\n",
    "#optional: user_bound, anime_bound, stop_bound\n",
    "\n",
    "#returns at most stop_bound pairs (user_id, anime_id) such that:\n",
    "# - used_id watched anime_id and rated it\n",
    "# - user_id watched at most user_bound animes\n",
    "# - anime id has been watched at least anime_bound times\n",
    "def select_newbies_probe(user_bound = 5, anime_bound = 0, stop_bound = 1000) :\n",
    "    ans = []\n",
    "    \n",
    "    perm = np.arange(len(records))\n",
    "    np.random.shuffle(perm)\n",
    "    \n",
    "    for p in perm :\n",
    "        user_id, anime_id, rating = records[p]\n",
    "        if(rating > 0 and count_anime[user_id] <= user_bound and count_users[anime_id] >= anime_bound) :\n",
    "            ans.append((user_id, anime_id))\n",
    "            if(len(ans) == stop_bound) :\n",
    "                break           \n",
    "    return ans\n",
    "\n",
    "def select_newbies_popular_probe(stop_bound = 1000) :\n",
    "    return select_newbies_probe(10, 10000, stop_bound)\n",
    "\n",
    "\n",
    "#optional: user_bound, anime_bound, stop_bound\n",
    "\n",
    "#returns at most stop_bound pairs (user_id, anime_id) such that:\n",
    "# - used_id watched anime_id and rated it\n",
    "# - user_id watched at least user_bound animes\n",
    "# - anime id has been watched at most anime_bound times\n",
    "def select_connoisseur_probe(user_bound = 100, anime_bound = 20, stop_bound = 1000) :\n",
    "    ans = []\n",
    "    \n",
    "    perm = np.arange(len(records))\n",
    "    np.random.shuffle(perm)\n",
    "    \n",
    "    for p in perm :\n",
    "        user_id, anime_id, rating = records[p]\n",
    "        if(rating > 0 and count_anime[user_id] >= user_bound and count_users[anime_id] <= anime_bound) :\n",
    "            ans.append((user_id, anime_id))\n",
    "            if(len(ans) == stop_bound) :\n",
    "                break\n",
    "                \n",
    "    print(len(ans))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arguments: k - parameter for k nearest neighbors algorithm,\n",
    "# test_pairs - testset in form of pairs (user_id, anime_id)\n",
    "#optional: function measuring errors\n",
    "\n",
    "#prints errors\n",
    "def make_test(k, test_pairs, measure = normalized_dist, include_minus_ones = False, error_func = error_avsq) :\n",
    "    estimated = []\n",
    "    expected = []\n",
    "    \n",
    "    estimated.append([])\n",
    "    expected.append([])\n",
    "    \n",
    "    N = len(test_pairs)\n",
    "    \n",
    "    for curr_k in range(1, k + 1):\n",
    "        estimated.append([])\n",
    "        expected.append([])\n",
    "    \n",
    "    i = 1\n",
    "    for t in test_pairs:\n",
    "        if(i % 10 == 0) :\n",
    "            print(i, end = \" \")\n",
    "        user_id, anime_id = t\n",
    "        \n",
    "        for curr_k in range(1, k + 1):\n",
    "            global neigh_number\n",
    "            neigh_number = curr_k\n",
    "            estimated[curr_k].append(estimate_score(user_id, anime_id, measure, include_minus_ones, test = True, rounded = False))\n",
    "            expected[curr_k].append(ratings[user_id][anime_id])\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    for curr_k in range(1, k + 1):\n",
    "        estimated[curr_k] = np.array(estimated[curr_k])\n",
    "        expected[curr_k] = np.array(expected[curr_k])\n",
    "    \n",
    "    ret = []\n",
    "    \n",
    "    for curr_k in range(1, k + 1):\n",
    "        error = error_func(estimated[curr_k], expected[curr_k])\n",
    "        ret.append(error)\n",
    "        \n",
    "    return np.array(ret)    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "\n",
    "probe_size = 500\n",
    "\n",
    "random_probe = select_random_probe(stop_bound = probe_size)\n",
    "popular_probe = select_popular_probe(stop_bound = probe_size)\n",
    "newbies_probe = select_newbies_popular_probe(stop_bound = probe_size)\n",
    "connoisseur_probe = select_connoisseur_probe(stop_bound = probe_size)\n",
    "\n",
    "np.savetxt('random.txt', random_probe, fmt = '%d')\n",
    "np.savetxt('popular.txt', popular_probe, fmt = '%d')\n",
    "np.savetxt('newbies.txt', newbies_probe, fmt = '%d')\n",
    "np.savetxt('connoisseur.txt', connoisseur_probe, fmt = '%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 10 20 30 40 50 60 70 80 "
     ]
    }
   ],
   "source": [
    "k_bound = 200\n",
    "\n",
    "errors = np.zeros((4, 4, k_bound))\n",
    "\n",
    "errors[0][0] = make_test(k_bound, random_probe, normalized_dist)\n",
    "errors[0][1] = make_test(k_bound, random_probe, count_common_dist, True)\n",
    "errors[0][2] = make_test(k_bound, random_probe, correlation_dist)\n",
    "errors[0][3] = make_test(k_bound, random_probe, cosine_dist)\n",
    "\n",
    "errors[1][0] = make_test(k_bound, popular_probe, normalized_dist)\n",
    "errors[1][1] = make_test(k_bound, popular_probe, count_common_dist, True)\n",
    "errors[1][2] = make_test(k_bound, popular_probe, correlation_dist)\n",
    "errors[1][3] = make_test(k_bound, popular_probe, cosine_dist)\n",
    "\n",
    "errors[2][0] = make_test(k_bound, newbies_probe, normalized_dist)\n",
    "errors[2][1] = make_test(k_bound, newbies_probe, count_common_dist, True)\n",
    "errors[2][2] = make_test(k_bound, newbies_probe, correlation_dist)\n",
    "errors[2][3] = make_test(k_bound, newbies_probe, cosine_dist)\n",
    "\n",
    "errors[3][0] = make_test(k_bound, connoisseur_probe, normalized_dist)\n",
    "errors[3][1] = make_test(k_bound, connoisseur_probe, count_common_dist, True)\n",
    "errors[3][2] = make_test(k_bound, connoisseur_probe, correlation_dist)\n",
    "errors[3][3] = make_test(k_bound, connoisseur_probe, cosine_dist)\n",
    "\n",
    "filenames = ['cf_errors_random.txt', 'cf_errors_popular.txt', 'cf_errors_newbies.txt', 'cf_errors_connoisseur.txt']\n",
    "\n",
    "for i in range(0, 4) :\n",
    "    cur = np.array([])\n",
    "    for j in range(0, 4) :\n",
    "        #print(cur, errors[i][j])\n",
    "        cur = np.concatenate((cur, errors[i][j]))\n",
    "    np.savetxt(filenames[i], cur, fmt = '%.5f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = np.arange(1, 21)\n",
    "errors_popular = [3.999, 2.92875, 2.564333333333333, 2.33825, 2.22516, 2.1125, 2.076183673469388, 2.03540625, 1.994061728395062, 1.95746, 1.9221074380165286, 1.8937013888888892, 1.8582544378698227, 1.8449285714285713, 1.82704, 1.81278515625, 1.7988996539792388, 1.788070987654321, 1.7705706371191137, 1.7491825]\n",
    "errors_random =  [3.417, 2.49575, 2.1923333333333335, 2.0124375, 1.8742800000000002, 1.8394444444444444, 1.8093673469387757, 1.77153125, 1.7558024691358025, 1.7349400000000001, 1.703495867768595, 1.6764166666666667, 1.6660591715976334, 1.661107142857143, 1.6432253287981862, 1.6437992350481858, 1.6315660900438607, 1.6336039707734944, 1.628074414670762, 1.6252053287981862]\n",
    "\n",
    "plt.plot(ks, errors_popular, 'bs', label = 'popular sample')\n",
    "plt.plot(ks, errors_random, 'r^', label = 'random sample')\n",
    "plt.ylabel('Average square error')\n",
    "plt.xlabel('K in KNN algorithm')\n",
    "plt.title('Collaborative filtering - accuracy measure on random samples (1000 queries in sample)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
